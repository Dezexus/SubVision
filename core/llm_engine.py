import gc
import re
from difflib import SequenceMatcher
from .utils import clean_llm_text

try:
    from huggingface_hub import hf_hub_download
    from llama_cpp import Llama
    HAS_LLM = True
except ImportError:
    HAS_LLM = False

class GemmaBatchFixer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å—É–±—Ç–∏—Ç—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ Gemma.
    """
    def __init__(self, log_func):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∏–∫—Å–µ—Ä.

        Args:
            log_func (callable): –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π.
        """
        self.log = log_func
        self.model_path = None
        self.llm = None

    def load_model(self):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç GGUF-–º–æ–¥–µ–ª—å Gemma –∏–∑ Hugging Face Hub.

        Returns:
            bool: True –≤ —Å–ª—É—á–∞–µ —É—Å–ø–µ—Ö–∞, –∏–Ω–∞—á–µ False.
        """
        if not HAS_LLM:
            self.log("‚ùå Llama-cpp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –ò–ò –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
            return False
        
        repo_id = "bartowski/google_gemma-3-4b-it-GGUF"
        filename = "google_gemma-3-4b-it-Q4_K_M.gguf"
        self.log(f"–ó–∞–≥—Ä—É–∑–∫–∞ AI –º–æ–¥–µ–ª–∏: {filename}...")
        
        try:
            self.model_path = hf_hub_download(repo_id=repo_id, filename=filename)
            self.llm = Llama(
                model_path=self.model_path,
                n_gpu_layers=-1,
                n_ctx=4096,
                verbose=False
            )
            return True
        except Exception as e:
            self.log(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ LLM: {e}")
            return False

    def fix_all_in_one_go(self, all_subtitles, lang='en'):
        """
        –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º –∫ LLM.

        Args:
            all_subtitles (list): –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏.
            lang (str): –Ø–∑—ã–∫ —Å—É–±—Ç–∏—Ç—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'en', 'ru').
        """
        if not self.llm or not all_subtitles:
            return

        self.log("ü§ñ –§–æ—Ä–º–∏—Ä—É—é –µ–¥–∏–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è LLM —Å–æ –≤—Å–µ–º —Ç–µ–∫—Å—Ç–æ–º...")
        lines_block = "\\n".join([f"{item['id']}. {item['text']}" for item in all_subtitles])
        lang_map = {'ru': 'Russian', 'en': 'English', 'de': 'German', 'fr': 'French'}
        target_lang = lang_map.get(lang, 'the target language')

        prompt = (
            f"<start_of_turn>user\\n"
            f"You are a professional subtitle editor. Your task is to carefully read the entire subtitle text provided below and correct any grammatical, punctuation, or spelling errors.\\n\\n"
            f"KEY RULES:\\n"
            f"1. Preserve fictional names and terms (e.g., 'Exostrider') if they appear consistently. They are not mistakes.\\n"
            f"2. Do not rephrase sentences. Only fix clear errors.\\n"
            f"3. Preserve original punctuation.\\n"
            f"4. The input is a numbered list. Your output must be a numbered list matching the original line numbers.\\n"
            f"5. IMPORTANT: Only include lines that you have corrected in your output. If a line is perfect, do not include it.\\n\\n"
            f"Here is the full subtitle text for correction in {target_lang}:\\n"
            f"---\\n"
            f"{lines_block}\\n"
            f"---\\n\\n"
            f"OUTPUT (Corrected lines only, as a numbered list):<end_of_turn>\\n"
            f"<start_of_turn>model\\n"
        )
        
        try:
            self.log("üß† –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ–∫—Å—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏... (–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è)")
            output = self.llm(prompt, max_tokens=2048, stop=["<end_of_turn>"], echo=False, temperature=0.1)
            raw_response = output['choices'][0]['text'].strip()
            fixed_lines = raw_response.split('\\n')
            
            self.log("‚úÖ –ù–µ–π—Ä–æ—Å–µ—Ç—å –∑–∞–≤–µ—Ä—à–∏–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É. –ü—Ä–∏–º–µ–Ω—è—é –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è...")
            pattern = re.compile(r'^(\\d+)[\\.\\)]\\s*(.*)')
            subs_by_id = {str(sub['id']): sub for sub in all_subtitles}
            correction_count = 0

            for line in fixed_lines:
                match = pattern.match(line.strip())
                if match:
                    id_str, raw_text = match.groups()
                    clean_text = clean_llm_text(raw_text)
                    
                    if not clean_text or id_str not in subs_by_id:
                        continue
                        
                    original_text = subs_by_id[id_str]['text']
                    if original_text.strip().lower() != clean_text.strip().lower():
                        similarity = SequenceMatcher(None, original_text.lower(), clean_text.lower()).ratio()
                        if similarity > 0.5:
                            subs_by_id[id_str]['text'] = clean_text
                            correction_count += 1
                        else:
                            self.log(f"‚ö†Ô∏è LLM –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∞ —Å–ª–∏—à–∫–æ–º –Ω–µ–ø–æ—Ö–æ–∂–µ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Å—Ç—Ä–æ–∫–∏ #{id_str}, –∏–≥–Ω–æ—Ä–∏—Ä—É—é.")
            
            self.log(f"‚ú® –ü—Ä–∏–º–µ–Ω–µ–Ω–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π: {correction_count}")

        except Exception as e:
            self.log(f"CRITICAL: –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å LLM: {e}")
            return

    def unload(self):
        """
        –í—ã–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –∏–∑ –ø–∞–º—è—Ç–∏ –∏ –æ—á–∏—â–∞–µ—Ç VRAM.
        """
        if self.llm:
            del self.llm
            self.llm = None
            gc.collect()

